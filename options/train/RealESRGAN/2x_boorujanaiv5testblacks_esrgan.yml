# general settings
name: 2x_BooruJaNai_V1RC5TestBlacksRefactor_ESRGAN
scale: 2
num_gpu: auto
manual_seed: 0

high_order_degradation: False

# dataset and data loader settings
datasets:
  train:
    name: DIV2K
    type: PairedImageDataset
    dataroot_gt: D:\traiNNer-redux\datasets\train\4x-boorujanai base\hr\hr color doujin simple
    dataroot_lq: D:\traiNNer-redux\datasets\train\4x-boorujanai base\lr degraded base 4bc\lr color doujin simple degraded base 4bc
    # dataroot_gt: D:\traiNNer-redux\datasets\train\symlinks\4x-boorujanai-v1rc5remake\hr
    # dataroot_lq: D:\traiNNer-redux\datasets\train\symlinks\4x-boorujanai-v1rc5remake\lr
    # meta_info: D:\traiNNer-redux\traiNNer\data\meta_info\4x-boorujanai-v1rc5remake.txt
    io_backend:
      type: disk

    gt_size: 384 #during training, it will crop a square of this size from your images, larger is usually better but uses more vram
    use_hflip: true #randomly flip the images horizontally
    use_rot: true #randomly rotate the images

    # data loader
    num_worker_per_gpu: 8
    batch_size_per_gpu: 6
    dataset_enlarge_ratio: 1
    prefetch_mode: ~

# network structures
network_g:
  type: ESRGAN
  use_pixel_unshuffle: true
  # in_nc: 3
  # out_nc: 3
  # num_filters: 64
  # num_blocks: 23

# network_d:
#   type: UNetDiscriminatorSN
#   num_in_ch: 3
#   num_feat: 64
#   skip_connection: True

# path
path:
  pretrain_network_g: D:\traiNNer-redux\experiments\pretrained_models\RealESRGAN_x2plus.pth
  param_key_g: params_ema
  strict_load_g: true
  resume_state: ~ #D:\traiNNer-redux\experiments\4x_MangaJaNai_V1RC34oldloss_RRDBNet\training_states\685000.state

# training settings
train:
  ema_decay: 0.999
  optim_g:
    type: AdamW
    lr: !!float 1e-4
      #paper uses this:
      #lr: !!float 5e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  # optim_d:
  #   type: AdamW
  #   lr: !!float 1e-4
  #     #paper uses this:
  #     #lr: !!float 5e-4
  #   weight_decay: 0
  #   betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [400000]
    gamma: 0.5

  total_iter: 500000
  warmup_iter: -1  # no warm up

  # losses
  mssim_opt:
    type: MSSIMLoss
    loss_weight: 1.0
  # pixel_opt:
  #   type: CharbonnierLoss
  #   loss_weight: 1.0
  #   reduction: mean
  # # perceptual loss (content and style losses)
  # perceptual_opt:
  #   type: PerceptualLoss
  #   layer_weights:
  #     # before relu
  #     "conv1_2": 0.1
  #     "conv2_2": 0.1
  #     "conv3_4": 1
  #     "conv4_4": 1
  #     "conv5_4": 1
  #   vgg_type: vgg19
  #   use_input_norm: true
  #   perceptual_weight: !!float 0.15
  #   style_weight: 0
  #   range_norm: false
  #   criterion: charbonnier
  # color_opt:
  #   type: ColorLoss
  #   criterion: "charbonnier"
  #   loss_weight: 1.0
  # # gan loss
  # gan_opt:
  #   type: GANLoss
  #   gan_type: vanilla
  #   real_label_val: 1.0
  #   fake_label_val: 0.0
  #   loss_weight: 0.1

  # Mix of Augmentations (MoA)
  use_moa: false
  # moa_augs: ['none', 'mixup', 'cutmix', 'resizemix', 'cutblur']
  # moa_probs: [0.4, 0.084, 0.084, 0.084, 0.348]
  moa_augs: ['cutmix']
  moa_probs: [1]
  moa_debug: true
  moa_debug_limit: 100

# logging settings
logger:
  print_freq: 100
  save_checkpoint_freq: 1000
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

# dist training settings
dist_params:
  backend: nccl
  port: 29500
