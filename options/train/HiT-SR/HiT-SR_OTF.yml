####################
# General Settings
####################
name: 4x_HiT_SRF_OTF
scale: 4  # 1, 2, 3, 4, 8
use_amp: true  # Speed up training and reduce VRAM usage.
amp_bf16: true  # Use bf16 instead of fp16 for AMP, RTX 3000 series or newer only.
fast_matmul: false  # Trade precision for performance.
num_gpu: auto
# manual_seed: 1024  # Deterministic mode, slows down training.

high_order_degradation: true  # Enable on-the-fly (OTF) degradations, which generates LR tiles from HRs during training.
high_order_degradations_debug: false  # Save the LR and HR tiles to debug/otf folder inside the root of the training directory.
high_order_degradations_debug_limit: 100  # The max number of iterations to save LR and HR tiles for.

# The first degradation process.
blur_prob: 0.0
resize_prob: [0.2, 0.7, 0.1]  # up, down, keep
resize_mode_list: ['bilinear', 'bicubic', 'nearest-exact']  # See modes: https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html
resize_mode_prob: [0.3333, 0.3333, 0.3333]  # Probability each resize mode is selected.
resize_range: [0.4, 1.5]
gaussian_noise_prob: 0.0
noise_range: [0, 0]
poisson_scale_range: [0, 0]
gray_noise_prob: 0.0
jpeg_prob: 1.0
jpeg_range: [75, 95]

# The second degradation process.
blur_prob2: 0.0
resize_prob2: [0.3, 0.4, 0.3]  # up, down, keep
resize_mode_list2: ['bilinear', 'bicubic', 'nearest-exact']  # See modes: https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html
resize_mode_prob2: [0.3333, 0.3333, 0.3333]  # Probability each resize mode is selected.
resize_range2: [0.6, 1.2]
gaussian_noise_prob2: 0
noise_range2: [0, 0]
poisson_scale_range2: [0, 0]
gray_noise_prob2: 0.0
jpeg_prob2: 1.0
jpeg_range2: [75, 95]

# The final resize to the target resolution.
resize_mode_list3: ['bilinear', 'bicubic', 'nearest-exact']  # See modes: https://pytorch.org/docs/stable/generated/torch.nn.functional.interpolate.html
resize_mode_prob3: [0.3333, 0.3333, 0.3333]  # Probability each resize mode is selected.

queue_size: 180
#################################
# Dataset and Dataloader Settings
#################################
datasets:
  # Settings for the training dataset.
  train:
    name: Train Dataset
    type: RealESRGANDataset
    # Path to the HR (high res) images in your training dataset.
    dataroot_gt: datasets/train/dataset1/hr
    # meta_info: data/meta_info/dataset1.txt
    io_backend:
      type: disk

    blur_kernel_size: 12
    kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
    kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
    sinc_prob: 0.0
    blur_sigma: [0.2, 2]
    betag_range: [0.5, 4]
    betap_range: [1, 2]

    blur_kernel_size2: 12
    kernel_list2: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
    kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
    sinc_prob2: 0.0
    blur_sigma2: [0.2, 1]
    betag_range2: [0.5, 4]
    betap_range2: [1, 2]

    final_sinc_prob: 0.0
    gt_size: 128  # During training, it will crop a square of this size from your HR images. Larger is usually better but uses more VRAM.
    use_hflip: true  # Randomly flip the images horizontally.
    use_rot: true  # Randomly rotate the images.

    num_worker_per_gpu: 8
    batch_size_per_gpu: 6  # Increasing stabilizes training but going too high can cause issues
    dataset_enlarge_ratio: auto  # Increase if the dataset is less than 1000 images to avoid slowdowns. Auto will automatically enlarge small datasets only.
    prefetch_mode: ~
  # Settings for your validation dataset (optional). These settings will
  # be ignored if val_enabled is false in the Validation section below.
  val:
    name: Val Dataset
    type: PairedImageDataset
    dataroot_gt: datasets/val/dataset1/hr
    dataroot_lq: datasets/val/dataset1/lr
    io_backend:
      type: disk

#####################
# Network Settings
#####################
# Generator model settings
network_g:
  type: HiT_SRF  # HiT_SRF, HiT_SNG, HiT_SIR

# Discriminator model settings
network_d:
  type: UNetDiscriminatorSN
  num_in_ch: 3
  num_feat: 64
  skip_connection: true

############################
# Pretrain and Resume Paths
############################
path:
  #pretrain_network_g: experiments/pretrained_models/pretrain.pth
  param_key_g: ~
  strict_load_g: true    # Disable strict loading to partially load a pretrain model with a different scale
  resume_state: ~

#####################
# Training Settings
#####################
train:
  ema_decay: 0.999
  # Optimizer for generator model
  optim_g:
    type: AdamW
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  # Optimizer for discriminator model
  optim_d:
    type: AdamW
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [200000, 400000]
    gamma: 0.5

  total_iter: 500000  # Total number of iterations.
  warmup_iter: -1  # Gradually ramp up learning rates until this iteration, to stabilize early training. Use -1 to disable.

  # Losses - for any loss set the loss_weight to 0 to disable it.
  # MSSIM loss
  mssim_opt:
    type: MSSIMLoss
    loss_weight: 1.0
  # Perceptual loss
  perceptual_opt:
    type: PerceptualLoss
    layer_weights:
      # before relu
      "conv1_2": 0.1
      "conv2_2": 0.1
      "conv3_4": 1
      "conv4_4": 1
      "conv5_4": 1
    vgg_type: vgg19
    style_weight: 0
    range_norm: false
    criterion: charbonnier
    perceptual_weight: 0.03
  # DISTS loss
  # dists_opt:
  #   type: DISTSLoss  # DISTSLoss, ADISTSLoss
  #   use_input_norm: true
  #   loss_weight: 0.25
  # HSLuv loss (hue, saturation, lightness). Use one of HSLuv loss or ColorLoss + LumaLoss, not both.
  hsluv_opt:
    type: HSLuvLoss
    criterion: charbonnier
    loss_weight: 1.0
  # GAN loss
  gan_opt:
    type: GANLoss
    gan_type: vanilla
    real_label_val: 1.0
    fake_label_val: 0.0
    loss_weight: 0.1
  # Color loss (ITU-R BT.601)
  # color_opt:
  #   type: ColorLoss
  #   criterion: charbonnier
  #   loss_weight: 1.0
  # Luma loss (RGB to CIELAB L*)
  # luma_opt:
  #   type: LumaLoss
  #   criterion: charbonnier
  #   loss_weight: 1.0

  # Mix of Augmentations (MoA)
  use_moa: false  # Whether to enable mixture of augmentations, which augments the dataset on the fly to create more variety and help the model generalize.
  moa_augs: ['none', 'mixup', 'cutmix', 'resizemix', 'cutblur']  # The list of augmentations to choose from, only one is selected per iteration.
  moa_probs: [0.4, 0.084, 0.084, 0.084, 0.348]  # The probability each augmentation in moa_augs will be applied. Total should add up to 1.
  moa_debug: false  # Save images before and after augment to debug/moa folder inside of the root training directory.
  moa_debug_limit: 100  # The max number of iterations to save augmentation images for.

#############
# Validation
#############
val:
  val_enabled: false  # Whether to enable validations. If disabled, all validation settings below are ignored.
  val_freq: 1000  # How often to run validations, in iterations.
  save_img: true  # Whether to save the validation images during validation, in the experiments/<name>/visualization folder.

  metrics_enabled: true  # Whether to run metrics calculations during validation.
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 4  # Whether to crop border during validation.
      test_y_channel: false  # Whether to convert to Y(CbCr) for validation.
    dists:
      type: calculate_dists
      better: lower

##########
# Logging
##########
logger:
  print_freq: 100
  save_checkpoint_freq: 1000
  save_checkpoint_format: safetensors
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

dist_params:
  backend: nccl
  port: 29500
